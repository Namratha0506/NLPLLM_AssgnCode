{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namratha0506/NLPLLM_AssgnCode/blob/main/CodeForAssignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install transformers -q\n",
        "!pip install -U scikit-learn -q\n",
        "!pip install wordcloud -q\n",
        "\n",
        "# Import core libraries for data handling and regular expressions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Import visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Import NLP tools for text cleaning\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Import sklearn modules for data splitting and evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Import Hugging Face transformer classes for BERT\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Import PyTorch utilities for model building and training\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set computation device to GPU if available, else fallback to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Computation device set to: {device}\")"
      ],
      "metadata": {
        "id": "SJNKSOKIv6TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EarFdW8L9knD"
      },
      "outputs": [],
      "source": [
        "# Load the combined financial sentiment dataset (FiQA + Financial PhraseBank) from GitHub\n",
        "Findata = 'https://raw.githubusercontent.com/Namratha0506/NLPLLM_AssgnCode/refs/heads/main/data.csv'\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "Findata_Data = pd.read_csv(Findata)\n",
        "# Display the first few rows of the financial dataset\n",
        "print(Findata_Data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize all column names to lowercase\n",
        "Findata_Data.columns = [col.lower() for col in Findata_Data.columns]"
      ],
      "metadata": {
        "id": "QkMMnIu_v_vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show structure and types of the columns in the financial sentiment dataset\n",
        "print('\\nðŸ“Š Dataset Overview:\\n')\n",
        "print(Findata_Data.info())"
      ],
      "metadata": {
        "id": "huhrlT0q0LLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary statistics for any numeric columns\n",
        "print('\\nðŸ“ˆ Summary Statistics:\\n')\n",
        "print(Findata_Data.describe())"
      ],
      "metadata": {
        "id": "-2Q4KE270Ns0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count and display the number of duplicate entries in the dataset\n",
        "print('\\nðŸ” Number of Duplicate Records:', Findata_Data.duplicated().sum())"
      ],
      "metadata": {
        "id": "7MKyId700OeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate rows from the dataset\n",
        "Findata_Data = Findata_Data.drop_duplicates()\n",
        "# Confirm that all duplicate entries have been removed\n",
        "print('\\n Number of Duplicate Records After Removal:', Findata_Data.duplicated().sum())"
      ],
      "metadata": {
        "id": "NlftVOVw06kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in each column of the dataset\n",
        "print('\\n Missing Values by Column:\\n')\n",
        "print(Findata_Data.isnull().sum())"
      ],
      "metadata": {
        "id": "uitx7k8CwLHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new figure with defined size for better visibility\n",
        "plt.figure(figsize=(8, 5))\n",
        "# Plot the count of each sentiment label using seaborn\n",
        "sns.countplot(data=Findata_Data, x='sentiment', hue='sentiment', palette='Set2', legend=False)\n",
        "# Set the title of the plot\n",
        "plt.title('Sentiment Label Distribution in Financial Texts')\n",
        "# Label the x-axis and y-axis\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Sentences')\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rB-yNkD1wR9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the frequency of each sentiment category in the dataset\n",
        "Sentiment_counts = Findata_Data['sentiment'].value_counts()\n",
        "# Extract sentiment category names\n",
        "Sentiment_labels = Sentiment_counts.index\n",
        "# Extract the corresponding counts for each sentiment\n",
        "Sentiment_sizes = Sentiment_counts.values\n",
        "# Create a pie chart to visualize sentiment distribution percentages\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.pie(Sentiment_sizes,labels=Sentiment_labels,autopct='%1.1f%%',\n",
        "        startangle=140,colors=plt.cm.Set3.colors)\n",
        "# Set the title of the chart\n",
        "plt.title('Percentage Distribution of Sentiments')\n",
        "# Ensure the pie chart is a perfect circle\n",
        "plt.axis('equal')\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_SvKmqJNwkL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'sentiment' column to categorical data type\n",
        "Findata_Data['sentiment'] = Findata_Data['sentiment'].astype('category')\n",
        "# Create a new column with encoded numeric values for each sentiment class\n",
        "Findata_Data['sentiment_encoded'] = Findata_Data['sentiment'].cat.codes\n",
        "# Retrieve the original sentiment category names in order of their assigned numeric codes\n",
        "Sentiment_label_names = Findata_Data['sentiment'].cat.categories.tolist()\n",
        "# Print the numeric-to-text sentiment label mapping\n",
        "print(\"Sentiment label encoding:\\n\", dict(enumerate(Sentiment_label_names)))"
      ],
      "metadata": {
        "id": "6kCwuP1Ywwq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the original distribution of sentiment categories in the financial dataset\n",
        "fin_sentiment_counts = Findata_Data['sentiment_encoded'].value_counts()\n",
        "print(\"Original sentiment distribution in financial text:\\n\", fin_sentiment_counts)\n",
        "\n",
        "# Find the maximum class count for oversampling\n",
        "fin_max_count = fin_sentiment_counts.max()\n",
        "\n",
        "# List to collect oversampled subsets for each sentiment\n",
        "fin_oversampled_data = []\n",
        "\n",
        "# Loop through each sentiment code and balance its count by oversampling\n",
        "for sentiment_code in fin_sentiment_counts.index:\n",
        "    sentiment_rows = Findata_Data[Findata_Data['sentiment_encoded'] == sentiment_code]\n",
        "    rows_to_add = fin_max_count - len(sentiment_rows)\n",
        "\n",
        "    if rows_to_add > 0:\n",
        "        extra_rows = sentiment_rows.sample(rows_to_add, replace=True, random_state=123456)\n",
        "        sentiment_rows = pd.concat([sentiment_rows, extra_rows])\n",
        "\n",
        "    fin_oversampled_data.append(sentiment_rows)\n",
        "\n",
        "# Concatenate and shuffle the balanced sentiment dataset\n",
        "Balanced_FinSent_Data = pd.concat(fin_oversampled_data).sample(frac=1, random_state=123456).reset_index(drop=True)\n",
        "\n",
        "# Display the class distribution after balancing\n",
        "print(\"\\n Balanced sentiment distribution:\\n\", Balanced_FinSent_Data['sentiment_encoded'].value_counts())\n"
      ],
      "metadata": {
        "id": "akYj6aT9I1Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot to show the distribution of sentiment labels after oversampling\n",
        "plt.figure(figsize=(8, 5))\n",
        "# Count the number of samples in each sentiment category\n",
        "sns.countplot(data=Balanced_FinSent_Data, x='sentiment', hue='sentiment', palette='Set2', legend=False)\n",
        "# Set the plot title\n",
        "plt.title('Balanced Distribution of Sentiment Labels in Financial Texts')\n",
        "# Label the x-axis and y-axis\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Number of Sentences')\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hX-mXzUQJNNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column that stores the character length of each sentence\n",
        "Findata_Data['fin_sentence_length'] = Findata_Data['sentence'].apply(len)\n",
        "# Print descriptive statistics (mean, min, max, etc.) for sentence lengths\n",
        "print(\"\\n Sentence Length Statistics:\\n\", Findata_Data['fin_sentence_length'].describe())\n",
        "# Create a new figure for the sentence length distribution plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "# Plot a histogram with a density curve to show sentence length distribution\n",
        "sns.histplot(Findata_Data['fin_sentence_length'], bins=30, kde=True)\n",
        "# Set the title of the plot\n",
        "plt.title(\"Distribution of Sentence Lengths in Financial Texts\")\n",
        "# Label the x-axis and y-axis\n",
        "plt.xlabel(\"Sentence Length (in Characters)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TeTSZc1kwzrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure for visualizing sentence length variation across sentiment classes\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Generate a boxplot comparing sentence lengths for each sentiment category\n",
        "sns.boxplot(data=Findata_Data, x='sentiment', y='fin_sentence_length', hue='sentiment', palette='Set2', legend=False)\n",
        "# Set the title of the plot\n",
        "plt.title(\"Sentence Length by Sentiment\")\n",
        "# Label the x-axis and y-axis for sentiment and text length\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Sentence Length (in Characters)\")\n",
        "# Display the boxplot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DJpezV3kxDzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK resources for text preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "# Initialize lemmatizer and define stopwords for financial text\n",
        "fin_text_lemmatizer = WordNetLemmatizer()\n",
        "fin_stopwords_set = set(stopwords.words('english'))\n",
        "# Function to clean and preprocess a financial sentence\n",
        "def preprocess_fin_sentence(fin_raw_text):\n",
        "    \"\"\"\n",
        "    Preprocess a financial sentence by lowercasing, removing punctuation and stopwords, and lemmatizing words.\n",
        "\n",
        "    Parameters:\n",
        "    fin_raw_text (str): Raw sentence from financial news or reports.\n",
        "\n",
        "    Returns:\n",
        "    str: Cleaned and lemmatized sentence ready for modeling.\n",
        "    \"\"\"\n",
        "    fin_lower = fin_raw_text.lower()\n",
        "    fin_nopunct = re.sub(r'[^a-z\\s]', '', fin_lower)\n",
        "    fin_tokens = fin_nopunct.split()\n",
        "    fin_clean_tokens = [fin_text_lemmatizer.lemmatize(word) for word in fin_tokens if word not in fin_stopwords_set]\n",
        "    return ' '.join(fin_clean_tokens)\n",
        "# Apply preprocessing to the 'sentence' column\n",
        "Findata_Data['fin_sentence_cleaned'] = Findata_Data['sentence'].apply(preprocess_fin_sentence)\n",
        "# Show a preview of original and cleaned financial sentences\n",
        "Findata_Data[['sentence', 'fin_sentence_cleaned']].head()"
      ],
      "metadata": {
        "id": "usjV6L3UxcXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows of the balanced financial sentiment dataset\n",
        "Balanced_FinSent_Data.head()"
      ],
      "metadata": {
        "id": "SkT8FN9Mx4XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the balanced financial dataset into training and testing sets (80/20 split)\n",
        "fin_text_train, fin_text_test, fin_label_train, fin_label_test = train_test_split(\n",
        "    Balanced_FinSent_Data['sentence'],\n",
        "    Balanced_FinSent_Data['sentiment_encoded'],\n",
        "    test_size=0.2,\n",
        "    random_state=123456,\n",
        "    stratify=Balanced_FinSent_Data['sentiment_encoded']\n",
        ")\n",
        "# Convert target labels to categorical type for compatibility with modeling\n",
        "fin_label_train = fin_label_train.astype('category')\n",
        "fin_label_test = fin_label_test.astype('category')"
      ],
      "metadata": {
        "id": "UpJUVAFEBvo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained BERT tokenizer (uncased lowercase version)\n",
        "fin_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# Tokenize and encode the financial training and test sentences\n",
        "fin_encoded_train = fin_tokenizer(fin_text_train.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "fin_encoded_test = fin_tokenizer(fin_text_test.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
        "# Convert sentiment labels to PyTorch tensors\n",
        "fin_labels_train_tensor = torch.tensor(fin_label_train.cat.codes.values)\n",
        "fin_labels_test_tensor = torch.tensor(fin_label_test.cat.codes.values)\n",
        "# Create TensorDataset objects for training and testing\n",
        "fin_train_dataset = TensorDataset(fin_encoded_train['input_ids'], fin_encoded_train['attention_mask'], fin_labels_train_tensor)\n",
        "fin_test_dataset = TensorDataset(fin_encoded_test['input_ids'], fin_encoded_test['attention_mask'], fin_labels_test_tensor)"
      ],
      "metadata": {
        "id": "1A8NBpoqCKem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained BERT model for multi-class sentiment classification\n",
        "fin_model_bert = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=len(Sentiment_label_names)\n",
        ").to(device)\n",
        "\n",
        "# Set up the AdamW optimizer for BERT\n",
        "fin_optimizer = AdamW(fin_model_bert.parameters(), lr=1e-5)\n",
        "\n",
        "# Define the loss function for categorical sentiment prediction\n",
        "fin_loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "iF9wskBGCaEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for training and testing batches\n",
        "fin_sent_train_loader = DataLoader(fin_train_dataset, batch_size=8, shuffle=True)\n",
        "fin_sent_test_loader = DataLoader(fin_test_dataset, batch_size=8)\n",
        "# Lists to store accuracy and loss across epochs\n",
        "fin_sent_train_acc_list = []\n",
        "fin_sent_test_acc_list = []\n",
        "fin_sent_epoch_loss_list = []\n",
        "# Loop over training epochs\n",
        "for epoch in range(5):  # Adjust number of epochs if needed\n",
        "    fin_model_bert.train()\n",
        "    epoch_total_loss = 0\n",
        "    epoch_correct_preds = 0\n",
        "    epoch_total_samples = 0\n",
        "    # Training phase\n",
        "    for fin_batch in tqdm(fin_sent_train_loader, desc=f\"Epoch {epoch+1} - Training\"):\n",
        "        fin_input_ids, fin_attn_masks, fin_sent_labels = [b.to(device) for b in fin_batch]\n",
        "        fin_sent_labels = fin_sent_labels.long()\n",
        "        # Forward pass\n",
        "        fin_optimizer.zero_grad()\n",
        "        fin_bert_outputs = fin_model_bert(input_ids=fin_input_ids, attention_mask=fin_attn_masks)\n",
        "        fin_batch_loss = fin_loss_function(fin_bert_outputs.logits, fin_sent_labels)\n",
        "        # Backward pass and optimizer step\n",
        "        fin_batch_loss.backward()\n",
        "        fin_optimizer.step()\n",
        "        # Accumulate metrics\n",
        "        epoch_total_loss += fin_batch_loss.item()\n",
        "        fin_batch_preds = torch.argmax(fin_bert_outputs.logits, dim=1)\n",
        "        epoch_correct_preds += (fin_batch_preds == fin_sent_labels).sum().item()\n",
        "        epoch_total_samples += fin_sent_labels.size(0)\n",
        "    # Calculate training metrics\n",
        "    train_epoch_acc = epoch_correct_preds / epoch_total_samples\n",
        "    fin_sent_train_acc_list.append(train_epoch_acc)\n",
        "    fin_sent_epoch_loss_list.append(epoch_total_loss / len(fin_sent_train_loader))\n",
        "    # Evaluation phase\n",
        "    fin_model_bert.eval()\n",
        "    test_correct_preds = 0\n",
        "    test_total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for fin_batch in fin_sent_test_loader:\n",
        "            fin_input_ids, fin_attn_masks, fin_sent_labels = [b.to(device) for b in fin_batch]\n",
        "            fin_sent_labels = fin_sent_labels.long()\n",
        "            fin_bert_outputs = fin_model_bert(input_ids=fin_input_ids, attention_mask=fin_attn_masks)\n",
        "            fin_batch_preds = torch.argmax(fin_bert_outputs.logits, dim=1)\n",
        "            test_correct_preds += (fin_batch_preds == fin_sent_labels).sum().item()\n",
        "            test_total_samples += fin_sent_labels.size(0)\n",
        "    # Calculate test accuracy\n",
        "    test_epoch_acc = test_correct_preds / test_total_samples\n",
        "    fin_sent_test_acc_list.append(test_epoch_acc)\n",
        "    # Print metrics for the current epoch\n",
        "    print(f\"Epoch {epoch+1}:\")\n",
        "    print(f\"  Training Accuracy : {train_epoch_acc:.4f}\")\n",
        "    print(f\"  Testing Accuracy  : {test_epoch_acc:.4f}\")\n",
        "    print(f\"  Average Loss      : {epoch_total_loss / len(fin_sent_train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "EAVNSwh3CtzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of epoch numbers for plotting\n",
        "fin_num_epochs = list(range(1, len(fin_sent_train_acc_list) + 1))\n",
        "# Create the figure for the accuracy plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Plot training accuracy across epochs\n",
        "plt.plot(fin_num_epochs, fin_sent_train_acc_list, marker='o', label='Training Accuracy')\n",
        "# Plot testing accuracy across epochs\n",
        "plt.plot(fin_num_epochs, fin_sent_test_acc_list, marker='o', label='Testing Accuracy')\n",
        "# Add title and axis labels\n",
        "plt.title(\"Training vs Testing Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "# Add x-tick marks for each epoch\n",
        "plt.xticks(fin_num_epochs)\n",
        "# Display legend and the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ayAWwb-ZHJqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the BERT model to evaluation mode\n",
        "fin_model_bert.eval()\n",
        "# Create DataLoader for test data\n",
        "fin_sent_test_loader = DataLoader(fin_test_dataset, batch_size=8)\n",
        "# Initialize lists to collect predictions and true labels\n",
        "fin_sent_preds = []\n",
        "fin_sent_true = []\n",
        "# Perform model inference without gradient calculation\n",
        "with torch.no_grad():\n",
        "    for batch in fin_sent_test_loader:\n",
        "        fin_test_input_ids, fin_test_attn_masks, fin_test_labels = [b.to(device) for b in batch]\n",
        "        fin_test_outputs = fin_model_bert(input_ids=fin_test_input_ids, attention_mask=fin_test_attn_masks)\n",
        "        fin_predicted_labels = torch.argmax(fin_test_outputs.logits, dim=1)\n",
        "        fin_sent_preds.extend(fin_predicted_labels.cpu().numpy())\n",
        "        fin_sent_true.extend(fin_test_labels.cpu().numpy())\n",
        "# Compute and display overall test accuracy\n",
        "fin_test_overall_acc = accuracy_score(fin_sent_true, fin_sent_preds)\n",
        "print(f\"Test Accuracy on Financial Sentiment Data: {fin_test_overall_acc:.2f}\")\n",
        "# Print detailed classification metrics\n",
        "print(\"\\n Classification Report on Financial Sentiment Data:\\n\")\n",
        "print(classification_report(fin_sent_true, fin_sent_preds, target_names=Sentiment_label_names))\n"
      ],
      "metadata": {
        "id": "HeBDi9QJHZxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the confusion matrix using true and predicted sentiment labels\n",
        "fin_conf_matrix = confusion_matrix(fin_sent_true, fin_sent_preds)\n",
        "# Create a display object for the confusion matrix with class labels\n",
        "fin_conf_matrix_display = ConfusionMatrixDisplay(confusion_matrix=fin_conf_matrix, display_labels=Sentiment_label_names)\n",
        "# Plot the confusion matrix using a blue color map\n",
        "fin_conf_matrix_display.plot(cmap='Blues')\n",
        "# Add a title to the plot\n",
        "plt.title(\"Confusion Matrix for Financial Sentiment Classification\")\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LEdmZOX7IPlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select 5 test samples to compare predictions\n",
        "fin_test_sample_indices = np.random.choice(len(fin_text_test), 5, replace=False)\n",
        "# Loop through selected samples\n",
        "for idx in fin_test_sample_indices:\n",
        "    # Get the original test sentence\n",
        "    fin_sample_text = fin_text_test.iloc[idx]\n",
        "    # Get the actual sentiment label\n",
        "    fin_actual_label = Sentiment_label_names[fin_label_test.iloc[idx]]\n",
        "    # Tokenize and send the input to the model\n",
        "    fin_input_tokens = fin_tokenizer(fin_sample_text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        fin_model_output = fin_model_bert(**fin_input_tokens)\n",
        "    # Get predicted sentiment label\n",
        "    fin_predicted_label = Sentiment_label_names[torch.argmax(fin_model_output.logits, dim=1).item()]\n",
        "    # Print the sentence with actual and predicted labels\n",
        "    print(\"\\n Sample Financial Sentence:\")\n",
        "    print(fin_sample_text)\n",
        "    print(\"Original Sentiment   :\", fin_actual_label)\n",
        "    print(\"Predicted Sentiment :\", fin_predicted_label)"
      ],
      "metadata": {
        "id": "xfT6-Tv-IlcI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}